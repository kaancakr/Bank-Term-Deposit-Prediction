{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b919f77",
   "metadata": {},
   "source": [
    "# Bank Marketing - SMOTE + F1 Pipeline\n",
    "\n",
    "This notebook rebuilds the training workflow with SMOTE, cross-validated model selection (LogReg, RandomForest, XGBoost if available), and decision-threshold tuning to maximize F1. Artifacts are saved under `artifacts/` for the Streamlit app.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5578d8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using base dir: /Users/kaancakir/ADA442Project\n",
      "XGBoost available: False\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold,\n",
    "    cross_val_predict,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_PATH = BASE_DIR / \"bank-additional.csv\"\n",
    "ARTIFACT_DIR = BASE_DIR / \"artifacts\"\n",
    "MODEL_PATH = ARTIFACT_DIR / \"final_model.pkl\"\n",
    "METRICS_PATH = ARTIFACT_DIR / \"metrics.json\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "ARTIFACT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "print(f\"Using base dir: {BASE_DIR}\")\n",
    "print(f\"XGBoost available: {HAS_XGB}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3357682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          job  marital          education default housing loan  \\\n",
      "0   30  blue-collar  married           basic.9y      no     yes   no   \n",
      "1   39     services   single        high.school      no      no   no   \n",
      "2   25     services  married        high.school      no     yes   no   \n",
      "3   38     services  married           basic.9y      no     NaN  NaN   \n",
      "4   47       admin.  married  university.degree      no     yes   no   \n",
      "\n",
      "     contact month day_of_week  ...  pdays  previous     poutcome  \\\n",
      "0   cellular   may         fri  ...     -1         0  nonexistent   \n",
      "1  telephone   may         fri  ...     -1         0  nonexistent   \n",
      "2  telephone   jun         wed  ...     -1         0  nonexistent   \n",
      "3  telephone   jun         fri  ...     -1         0  nonexistent   \n",
      "4   cellular   nov         mon  ...     -1         0  nonexistent   \n",
      "\n",
      "   emp.var.rate cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \\\n",
      "0          -1.8         92.893          -46.2      1.313       5099.1  0   \n",
      "1           1.1         93.994          -36.4      4.855       5191.0  0   \n",
      "2           1.4         94.465          -41.8      4.962       5228.1  0   \n",
      "3           1.4         94.465          -41.8      4.959       5228.1  0   \n",
      "4          -0.1         93.200          -42.0      4.191       5195.8  0   \n",
      "\n",
      "   was_contacted  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Rows: 4119\n",
      "Positive rate: 0.10949259529011895\n",
      "Categorical columns: 10\n",
      "Numeric columns: 11\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(DATA_PATH, sep=\";\")\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Basic cleaning\n",
    "df = df.replace(\"unknown\", np.nan)\n",
    "df[\"was_contacted\"] = (df[\"pdays\"] != 999).astype(int)\n",
    "df[\"pdays\"] = df[\"pdays\"].replace(999, -1)\n",
    "df[\"y\"] = df[\"y\"].map({\"no\": 0, \"yes\": 1})\n",
    "\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = [c for c in df.columns if c not in cat_cols + [\"y\"]]\n",
    "\n",
    "print(df.head())\n",
    "print(\"\\nRows:\", len(df))\n",
    "print(\"Positive rate:\", df[\"y\"].mean())\n",
    "print(\"Categorical columns:\", len(cat_cols))\n",
    "print(\"Numeric columns:\", len(num_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "869ffac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (3295, 21), Test size: (824, 21), Train positive rate: 0.110\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[\"y\"])\n",
    "y = df[\"y\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Train size: {X_train.shape}, Test size: {X_test.shape}, Train positive rate: {y_train.mean():.3f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9867e6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess and CV ready\n"
     ]
    }
   ],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "print(\"Preprocess and CV ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a354db02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running search for logreg ...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best F1 for logreg: 0.5828 in 0.1 min\n",
      "\n",
      "Running search for rf ...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best F1 for rf: 0.5982 in 0.4 min\n",
      "\n",
      "Winner: rf\n",
      "Best params: {'clf__n_estimators': 250, 'clf__min_samples_leaf': 2, 'clf__max_features': None, 'clf__max_depth': 10}\n",
      "CV F1: 0.5982\n"
     ]
    }
   ],
   "source": [
    "model_spaces = [\n",
    "    (\n",
    "        \"logreg\",\n",
    "        LogisticRegression(max_iter=600, solver=\"liblinear\"),\n",
    "        {\n",
    "            \"clf__C\": [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "            \"clf__penalty\": [\"l2\"],\n",
    "            \"clf__class_weight\": [None, \"balanced\"],\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"rf\",\n",
    "        RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1),\n",
    "        {\n",
    "            \"clf__n_estimators\": [150, 250, 400],\n",
    "            \"clf__max_depth\": [None, 10, 20],\n",
    "            \"clf__min_samples_leaf\": [1, 2, 4],\n",
    "            \"clf__max_features\": [\"sqrt\", \"log2\", None],\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "if HAS_XGB:\n",
    "    model_spaces.append(\n",
    "        (\n",
    "            \"xgb\",\n",
    "            XGBClassifier(\n",
    "                eval_metric=\"logloss\",\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_jobs=-1,\n",
    "                tree_method=\"hist\",\n",
    "            ),\n",
    "            {\n",
    "                \"clf__n_estimators\": [200, 400],\n",
    "                \"clf__max_depth\": [3, 5, 7],\n",
    "                \"clf__learning_rate\": [0.03, 0.1, 0.2],\n",
    "                \"clf__subsample\": [0.8, 1.0],\n",
    "                \"clf__colsample_bytree\": [0.8, 1.0],\n",
    "                \"clf__reg_lambda\": [1.0, 3.0, 5.0],\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for name, clf, param_grid in model_spaces:\n",
    "    pipe = ImbPipeline(\n",
    "        steps=[(\"preprocess\", preprocess), (\"smote\", SMOTE(random_state=RANDOM_STATE)), (\"clf\", clf)]\n",
    "    )\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=min(12, np.prod([len(v) for v in param_grid.values()])),\n",
    "        scoring=\"f1\",\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nRunning search for {name} ...\")\n",
    "    start = time.time()\n",
    "    search.fit(X_train, y_train)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"Best F1 for {name}: {search.best_score_:.4f} in {elapsed/60:.1f} min\")\n",
    "\n",
    "    search_results.append({\n",
    "        \"name\": name,\n",
    "        \"search\": search,\n",
    "        \"cv_f1\": search.best_score_,\n",
    "        \"best_params\": search.best_params_,\n",
    "        \"elapsed_min\": elapsed / 60,\n",
    "    })\n",
    "\n",
    "best_entry = max(search_results, key=lambda d: d[\"cv_f1\"])\n",
    "best_search = best_entry[\"search\"]\n",
    "best_estimator = best_search.best_estimator_\n",
    "\n",
    "print(\"\\nWinner:\", best_entry[\"name\"])\n",
    "print(\"Best params:\", best_entry[\"best_params\"])\n",
    "print(\"CV F1:\", round(best_entry[\"cv_f1\"], 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d38dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold on CV preds: 0.50 with F1 0.5988\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.458498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.491636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.514107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.535774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.547038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold        f1\n",
       "0       0.05  0.458498\n",
       "1       0.10  0.491636\n",
       "2       0.15  0.514107\n",
       "3       0.20  0.535774\n",
       "4       0.25  0.547038"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tune_threshold(model, X, y, cv_obj, grid=None):\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.05, 0.95, 19)\n",
    "    proba = cross_val_predict(model, X, y, cv=cv_obj, method=\"predict_proba\", n_jobs=-1)[:, 1]\n",
    "    scores = []\n",
    "    for thr in grid:\n",
    "        preds = (proba >= thr).astype(int)\n",
    "        scores.append((thr, f1_score(y, preds)))\n",
    "    best_thr, best_f1 = max(scores, key=lambda t: t[1])\n",
    "    return best_thr, best_f1, pd.DataFrame(scores, columns=[\"threshold\", \"f1\"])\n",
    "\n",
    "best_threshold, best_thr_f1, threshold_df = tune_threshold(best_estimator, X_train, y_train, cv)\n",
    "print(f\"Best threshold on CV preds: {best_threshold:.2f} with F1 {best_thr_f1:.4f}\")\n",
    "threshold_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "256833c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1: 0.5842, Precision: 0.5268, Recall: 0.6556, ROC-AUC: 0.9370\n",
      "Confusion matrix (rows=true, cols=pred): [[681, 53], [31, 59]]\n"
     ]
    }
   ],
   "source": [
    "final_model = best_estimator.fit(X_train, y_train)\n",
    "\n",
    "test_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "test_pred = (test_proba >= best_threshold).astype(int)\n",
    "\n",
    "test_f1 = f1_score(y_test, test_pred)\n",
    "test_precision = precision_score(y_test, test_pred)\n",
    "test_recall = recall_score(y_test, test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, test_proba)\n",
    "test_cm = confusion_matrix(y_test, test_pred).tolist()\n",
    "\n",
    "print(\n",
    "    f\"Test F1: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, ROC-AUC: {test_roc_auc:.4f}\"\n",
    ")\n",
    "print(\"Confusion matrix (rows=true, cols=pred):\", test_cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f848049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to /Users/kaancakir/ADA442Project/artifacts/final_model.pkl\n",
      "Saved metrics to /Users/kaancakir/ADA442Project/artifacts/metrics.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'rf',\n",
       " 'best_params': {'clf__n_estimators': 250,\n",
       "  'clf__min_samples_leaf': 2,\n",
       "  'clf__max_features': None,\n",
       "  'clf__max_depth': 10},\n",
       " 'cv_f1': 0.5982215372405179,\n",
       " 'threshold': 0.49999999999999994,\n",
       " 'threshold_cv_f1': 0.5988439306358382,\n",
       " 'test': {'f1': 0.5841584158415841,\n",
       "  'precision': 0.5267857142857143,\n",
       "  'recall': 0.6555555555555556,\n",
       "  'roc_auc': 0.9369663941871027,\n",
       "  'confusion_matrix': [[681, 53], [31, 59]]},\n",
       " 'class_balance': {'train_yes_rate': 0.10955993930197269,\n",
       "  'test_yes_rate': 0.10922330097087378},\n",
       " 'artifacts': {'model_path': '/Users/kaancakir/ADA442Project/artifacts/final_model.pkl',\n",
       "  'metrics_path': '/Users/kaancakir/ADA442Project/artifacts/metrics.json'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {\n",
    "    \"model\": best_entry[\"name\"],\n",
    "    \"best_params\": best_entry[\"best_params\"],\n",
    "    \"cv_f1\": float(best_entry[\"cv_f1\"]),\n",
    "    \"threshold\": float(best_threshold),\n",
    "    \"threshold_cv_f1\": float(best_thr_f1),\n",
    "    \"test\": {\n",
    "        \"f1\": float(test_f1),\n",
    "        \"precision\": float(test_precision),\n",
    "        \"recall\": float(test_recall),\n",
    "        \"roc_auc\": float(test_roc_auc),\n",
    "        \"confusion_matrix\": test_cm,\n",
    "    },\n",
    "    \"class_balance\": {\n",
    "        \"train_yes_rate\": float(y_train.mean()),\n",
    "        \"test_yes_rate\": float(y_test.mean()),\n",
    "    },\n",
    "    \"artifacts\": {\n",
    "        \"model_path\": str(MODEL_PATH),\n",
    "        \"metrics_path\": str(METRICS_PATH),\n",
    "    },\n",
    "}\n",
    "\n",
    "joblib.dump(final_model, MODEL_PATH)\n",
    "METRICS_PATH.write_text(json.dumps(metrics, indent=2))\n",
    "\n",
    "print(f\"Saved model to {MODEL_PATH}\")\n",
    "print(f\"Saved metrics to {METRICS_PATH}\")\n",
    "metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
